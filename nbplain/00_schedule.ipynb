{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to the Anatra HPC service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Anatra High Performance Compute system serves University of Bath's research computing needs with specialized hardware configurations for different research domains. The cluster consists of 19 compute nodes organized into partitions based on hardware capabilities and departmental requirements.\n",
    "\n",
    "## üìä Partition Layout\n",
    "\n",
    "\n",
    "| **Partition** | **Nodes** | **Count** | **Description** |\n",
    "|:----------------:|:------------:|:------------:|:------------------|\n",
    "| üü¢ **nodes** | 001‚Äì008 | 8 nodes| General-purpose computing |\n",
    "| ‚öóÔ∏è **chemistry** | 009‚Äì016 | 8 nodes| Chemistry computing |\n",
    "| üß¨ **lifesci** | 017 | 1 node| Life Sciences computing |\n",
    "| üíé **chemgpu** | 018 | 1 node| GPU-based Chemistry computing |\n",
    "| üéØ **lifescigpu** | 019 | 1 node | GPU-based Life Sciences computing |\n",
    "\n",
    "## üíª Node Information\n",
    "\n",
    "After logging into the Anatra HPC system, users can view node and partition details using the following commands:\n",
    "\n",
    "**üí° View all partitions and nodes**\n",
    "```bash\n",
    "sinfo -Nel\n",
    "```\n",
    "\n",
    "**‚öôÔ∏è Show detailed node hardware and resource information**\n",
    "```bash\n",
    "scontrol show nodes\n",
    "```\n",
    "\n",
    "**üìä Summarize partitions, node states, and available resources**\n",
    "```bash\n",
    "sinfo -o \"%P %N %t %C %m %G\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "In order to complete the workshop you should be familiar with:\n",
    "* The linux command line\n",
    "* Accessing and submitting jobs to High Performance Computing clusters as a user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Schedule\n",
    "\n",
    "Approximate timings for the lesson:\n",
    "\n",
    "| Time | Episode | Description |\n",
    "|---|---|---|\n",
    "| -:-- | [Setup](./00_setup.ipynb) | Setup for the lesson |\n",
    "| 0:05 | [Accessing Anatra](./01_episode.ipynb) | Logging onto the system |\n",
    "| 0:20 | [Slurm](./02_episode.ipynb) | A brief overview of slurm |\n",
    "| 0:30 | [Hardware](./03_episode.ipynb) | Overview of available hardware | \n",
    "| 0:40 | [Storage](./04_episode.ipynb) | Storage set-up and where to keep your data |\n",
    "| 0:50 | [Software](./05_episode.ipynb) | Using software modules |\n",
    "| 0:55 | [Running a job](./06_episode.ipynb) | Submitting a job |\n",
    "| 0:55 | [Starting a VNC session](./07_episode.ipynb) | Visualising data |\n",
    "| 0:55 | [Running GPU Jobs](./08_episode.ipynb) | Submitting GPU jobs for CUDA applications |\n",
    "| 0.55 | [Apptainer Containers](./09_episode.ipynb) | Running Containerized Jobs with Apptainer |"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
