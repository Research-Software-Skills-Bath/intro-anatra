{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview:\n",
    "- **Teaching:** 10 min\n",
    "- **Exercises:** 0 min\n",
    "\n",
    "**Questions**\n",
    "- What hardware is available?\n",
    "\n",
    "**Objectives**\n",
    "- Understand what compute resources are available on Anatra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Slurm partitions\n",
    "\n",
    "The new hpc service Anatra provides user access to an array of different compute instances. These instances are accessed through different slurm partitions.\n",
    "\n",
    "In order to list the partitions issue the following command:\n",
    "\n",
    "`sinfo`\n",
    "\n",
    "which will list the partitions, the nodes in the partitions, availability and the current state:\n",
    "\n",
    "\n",
    "```bash\n",
    "[bad45@loginnode1 ~]$\n",
    "‚ùØ sinfo\n",
    "PARTITION    AVAIL  TIMELIMIT  NODES  STATE NODELIST\n",
    "nodes*        up   infinite      8   idle node-[001-008]\n",
    "chemistry     up   infinite      5    mix node-[009-012,014]\n",
    "chemistry     up   infinite      3  alloc node-[013,015-016]\n",
    "chemgpu       up   infinite      1   idle node-018\n",
    "lifesci       up   infinite      1   idle node-017\n",
    "lifescigpu    up   infinite      1   idle node-019\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information: Hardware\n",
    "\n",
    "The Anatra cluster consists of a login node and nineteen compute nodes.\n",
    "\n",
    "### Login node\n",
    "The login node has the following resources:\n",
    "- 16 Cores\n",
    "- 100 GB memory\n",
    "- 2 TB of shared storage space\n",
    "\n",
    "\n",
    "### Compute nodes\n",
    "The compute nodes have the following resources:\n",
    "- 96 Cores (node-0[01-13])\n",
    "- 48 Cores (node-0[14-16])\n",
    "- 384 Cores (node-017/High Mem)\n",
    "- 256 GB memory (node-0[01-08])\n",
    "  - ~2.7 GB / core\n",
    "  - 4 NUMA zones per socket\n",
    "- 384 GB memory (node-0[09-13])\n",
    "  - ~4 GB / core\n",
    "- 768 GB memory (node-0[14-16])\n",
    "  - ~16 GB / core\n",
    "- 2.2 TB memory (node-017)\n",
    "  - ~5.7 GB / core\n",
    "- **ChemGpu** \n",
    "  - 96 Cores (node-018)\n",
    "  - ~8 GB / core\n",
    "  - ~GPU:l40s:1\n",
    "- **LifesciGpu** \n",
    "  - 256 Cores (node-019)\n",
    "  - ~4.3 GB / core\n",
    "  - ~GPU:h100:2\n",
    "\n",
    "It is worth noting that jobs which span multiple NUMA zones or sockets may see a notable decrease in performance if memory bandwidth limited. As such, it is rarely advisable to request 25 cores where 24 is sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points:\n",
    "- All compute resources are currently accessed via the `nodes*`,`chemistry`,`chemgpu`,`lifesci` & `lifescigpu` partition, whilst VNC sessions are run via the login node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
